{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4407e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D,\n",
    "    MaxPooling2D,\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    BatchNormalization,\n",
    ")\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.preprocessing.image import (\n",
    "    img_to_array,\n",
    "    load_img,\n",
    "    ImageDataGenerator,\n",
    ")\n",
    "from PIL import Image\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff367a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert .tif to .png\n",
    "def convert_tif_to_png(folder_path):\n",
    "    for img_path in glob.glob(folder_path + \"/*.tif\"):\n",
    "        img = Image.open(img_path)\n",
    "        if img.mode != \"RGB\":\n",
    "            img = img.convert(\"RGB\")\n",
    "        png_path = img_path.replace(\".tif\", \".png\")\n",
    "        img.save(png_path, \"PNG\")\n",
    "        os.remove(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3202376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess the images\n",
    "def preprocess_images(image_paths, target_size=(224, 224)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label, path in image_paths.items():\n",
    "        img = load_img(path, target_size=target_size)\n",
    "        img_array = img_to_array(img)\n",
    "        img_array = img_array / 255.0  # Normalize the images\n",
    "        images.append(img_array)\n",
    "        labels.append(int(label.split(\"_\")[0]))\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1048ef3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple CNN model\n",
    "def create_model(input_shape):\n",
    "    model = Sequential(\n",
    "        [\n",
    "            Conv2D(32, (3, 3), activation=\"relu\", input_shape=input_shape),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Flatten(),\n",
    "            Dense(256, activation=\"relu\"),\n",
    "            Dropout(0.5),\n",
    "            BatchNormalization(),\n",
    "            Dense(1, activation=\"linear\"),  # For regression output\n",
    "        ]\n",
    "    )\n",
    "    model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7aec4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process and tile images with overlap\n",
    "def process_and_tile_images_with_overlap(image_path, tile_size=(224, 224), overlap=0.4):\n",
    "    img = Image.open(image_path)\n",
    "    img_width, img_height = img.size\n",
    "    tiles = []\n",
    "    stride = int(tile_size[0] * (1 - overlap))\n",
    "\n",
    "    for x in range(0, img_width - tile_size[0], stride):\n",
    "        for y in range(0, img_height - tile_size[1], stride):\n",
    "            box = (x, y, x + tile_size[0], y + tile_size[1])\n",
    "            tile = img.crop(box)\n",
    "            tile_array = img_to_array(tile)\n",
    "            tile_array = tile_array / 255.0  # Normalize the tiles\n",
    "            tiles.append(tile_array)\n",
    "\n",
    "    return np.array(tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea560a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict and sum trees with post-processing and thresholding\n",
    "def predict_and_sum_trees(\n",
    "    model, image_path, tile_size=(224, 224), overlap_threshold=0.4, count_threshold=0.5\n",
    "):\n",
    "    tiles = process_and_tile_images_with_overlap(\n",
    "        image_path, tile_size=tile_size, overlap=overlap_threshold\n",
    "    )\n",
    "    tile_predictions = model.predict(tiles)\n",
    "    # Apply a threshold to the predictions to count only confident predictions\n",
    "    tile_predictions = (tile_predictions > count_threshold).astype(int)\n",
    "    # Adjust the post-processing logic if necessary\n",
    "    adjusted_count = np.sum(tile_predictions)\n",
    "    return adjusted_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52947d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, layer_id, filter_id, image):\n",
    "    layer = model.layers[layer_id]\n",
    "    layer_output = layer.output\n",
    "    submodel = tf.keras.models.Model(inputs=model.inputs, outputs=layer_output)\n",
    "\n",
    "    feature_map = submodel.predict(image[np.newaxis, ...])\n",
    "    if layer_output.shape[-1] > 1:  # Only visualize if the layer has filters\n",
    "        filter_activation = feature_map[0, :, :, filter_id]\n",
    "        plt.matshow(filter_activation, cmap=\"viridis\")\n",
    "        plt.title(f\"Layer {layer.name} Filter {filter_id}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fd2090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a directory to save/load augmented images\n",
    "augmented_images_dir = \"augmented_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b05ceab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save augmented images\n",
    "def save_augmented_images(images, labels, directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    for i, (image, label) in enumerate(zip(images, labels)):\n",
    "        filename = f\"augmented_image_{label}_{i}.png\"\n",
    "        image_path = os.path.join(directory, filename)\n",
    "        image = (image * 255).astype(np.uint8)  # Convert back to 0-255 range\n",
    "        img = Image.fromarray(image)\n",
    "        img.save(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01471127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load augmented images\n",
    "def load_augmented_images(directory):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for image_path in glob.glob(directory + \"/*.png\"):\n",
    "        label = int(os.path.basename(image_path).split(\"_\")[2])\n",
    "        img = load_img(image_path)\n",
    "        img_array = img_to_array(img)\n",
    "        img_array = img_array / 255.0  # Normalize the images\n",
    "        images.append(img_array)\n",
    "        labels.append(label)\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8beee6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming image_paths contains paths for all images and their labels\n",
    "image_paths = {\n",
    "    \"13_trees\": \"13_trees.png\",\n",
    "    \"15_trees\": \"15_trees.png\",\n",
    "    \"19_trees\": \"19_trees.png\",\n",
    "    \"20_trees\": \"20_trees.png\",\n",
    "    \"21_trees\": \"21_trees.png\",\n",
    "    \"1_trees\": \"example.png\",\n",
    "    \"22_trees\": \"22_trees.png\",\n",
    "    \"34_trees\": \"34_trees.png\",\n",
    "    \"35_trees\": \"35_trees.png\",\n",
    "    \"36_trees\": \"36_trees.png\",\n",
    "    \"41_trees\": \"41_trees.png\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b509c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the images\n",
    "images, labels = preprocess_images(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b9b412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data augmentation configuration\n",
    "data_generator = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode=\"nearest\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb37ba17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if augmented images exist, if not, create and save them\n",
    "if (\n",
    "    not os.path.exists(augmented_images_dir)\n",
    "    or len(os.listdir(augmented_images_dir)) == 0\n",
    "):\n",
    "    # Augment data to create a larger dataset\n",
    "    augmented_images, augmented_labels = [], []\n",
    "    for i in range(len(images)):\n",
    "        img, label = images[i], labels[i]\n",
    "        img = img[np.newaxis, ...]\n",
    "        num_augmented = 0\n",
    "        for batch in data_generator.flow(img, batch_size=1):\n",
    "            augmented_image = batch[0]\n",
    "            augmented_images.append(augmented_image)\n",
    "            augmented_labels.append(label)\n",
    "            num_augmented += 1\n",
    "            if num_augmented == (200 // len(images)):\n",
    "                break\n",
    "    augmented_images = np.array(augmented_images)\n",
    "    augmented_labels = np.array(augmented_labels)\n",
    "    save_augmented_images(augmented_images, augmented_labels, augmented_images_dir)\n",
    "else:\n",
    "    # Load augmented images\n",
    "    augmented_images, augmented_labels = load_augmented_images(augmented_images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598d1fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define K-fold cross validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa922deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform K-fold cross validation\n",
    "fold_no = 1\n",
    "for train_index, test_index in kf.split(images):\n",
    "    train_images, test_images = images[train_index], images[test_index]\n",
    "    train_labels, test_labels = labels[train_index], labels[test_index]\n",
    "\n",
    "    # Create a new model for each fold\n",
    "    model = create_model(input_shape=(224, 224, 3))\n",
    "    print(f\"Training fold {fold_no}...\")\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_images,\n",
    "        train_labels,\n",
    "        batch_size=5,\n",
    "        epochs=100,\n",
    "        validation_data=(test_images, test_labels),\n",
    "    )\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904d74bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After K-fold cross validation, you can train a final model on all available data\n",
    "final_model = create_model(input_shape=(224, 224, 3))\n",
    "final_model.fit(augmented_images, augmented_labels, batch_size=5, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff59f5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final model\n",
    "final_model.save(\"final_tree_counting_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adfa5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert .tif to .png before prediction if necessary\n",
    "unlabeled_folder_path = \"unlabeled\"\n",
    "convert_tif_to_png(unlabeled_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4981cc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_threshold = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d919675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the specific unlabeled image you want to count trees in\n",
    "unlabeled_image_name = \"PalmTreePlantation_transparent_mosaic_group1.png\"\n",
    "unlabeled_image_path = os.path.join(unlabeled_folder_path, unlabeled_image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6ef957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and count trees in the unlabeled image\n",
    "tree_count = predict_and_sum_trees(\n",
    "    final_model,\n",
    "    unlabeled_image_path,\n",
    "    tile_size=(224, 224),\n",
    "    overlap_threshold=overlap_threshold,\n",
    ")\n",
    "print(f\"Image: {unlabeled_image_name}, Predicted Tree Count: {tree_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b252a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_index = 0  # Index of the image to visualize\n",
    "visualize_model(\n",
    "    final_model, layer_id=0, filter_id=0, image=augmented_images[example_index]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
